{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f918033-187e-4acd-aee9-3a8486d1bb88",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"iris_kubeflow.png\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84691e96-f919-4c01-8cbc-6d7ec4360ec1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Iris Dataset Example\n",
    "The [Iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) a dataset consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) and their features(sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)). The goal of our model will be to use these features to predict  iris species.  We will be training an [XGboost](https://xgboost.readthedocs.io/en/stable/) model. Run the below cells in order to train your XGboost model and view predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c466550-db30-4e07-823f-658f53e31c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from xgboost) (1.11.3)\n",
      "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "#Install XGboost\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42f33d7-8fa9-4c89-b1e3-28619db01483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import our packages\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557640a3-35cc-4843-86e2-92ae1eb7c748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2962ec19-9d97-4fd0-a5d3-93586cb0f47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "  species  \n",
      "0  setosa  \n",
      "1  setosa  \n",
      "2  setosa  \n",
      "3  setosa  \n",
      "4  setosa  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add the Target Variable\n",
    "df_iris['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_iris.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1602cfa-91f0-4242-9736-29e248d46b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7a82e504-ccd0-4ed0-b563-83155e166a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train XGBoost model\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "329af05f-a2cc-4786-86e6-2873837fd0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16561a-1d3d-4f14-8fa7-f7f8087162e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unpacking our Predictions \n",
    "Let's go ahead and take a look at a sample request and response to and from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8e5a772a-0696-46fe-a6f2-761ed4c9b543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample: [5.1, 3.5, 1.4, 0.2] - Predicted species: setosa\n",
      "Test sample: [6.0, 2.2, 4.0, 1.0] - Predicted species: versicolor\n",
      "Test sample: [6.3, 3.3, 6.0, 2.5] - Predicted species: virginica\n",
      "Test sample: [1.0, 1.2, 5.0, 3.1] - Predicted species: virginica\n"
     ]
    }
   ],
   "source": [
    "# Example: A new flower with these measurements\n",
    "test_samples = [\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Setosa\n",
    "    [6.0, 2.2, 4.0, 1.0],  # Versicolor\n",
    "    [6.3, 3.3, 6.0, 2.5], # Virginica\n",
    "    [1.0,1.2,5.0,3.1], #random flower \n",
    "]\n",
    "\n",
    "for sample in test_samples:\n",
    "    sample_prediction = model.predict([sample])\n",
    "    predicted_species = iris.target_names[sample_prediction[0]]\n",
    "    print(f\"Test sample: {sample} - Predicted species: {predicted_species}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c3bde-06e0-45ad-ad18-2ce54bb7dd64",
   "metadata": {},
   "source": [
    "We could also adjust our sample_input and see what species we get! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61252994-7974-429c-9d71-e966e3ea38a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random flower features: [4.4132081184715, 3.260956323282673, 6.739219351767208, 0.16823570237241894] - Predicted species: virginica\n"
     ]
    }
   ],
   "source": [
    "random_flower = [\n",
    "    random.uniform(4.3, 7.9),  # Sepal length\n",
    "    random.uniform(2.0, 4.4),  # Sepal width\n",
    "    random.uniform(1.0, 6.9),  # Petal length\n",
    "    random.uniform(0.1, 2.5)   # Petal width\n",
    "]\n",
    "\n",
    "# Predict the species of the random flower\n",
    "sample_prediction = model.predict([random_flower])\n",
    "predicted_species = iris.target_names[sample_prediction[0]]\n",
    "print(f\"Random flower features: {random_flower} - Predicted species: {predicted_species}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7669b9-0ffe-4263-afd4-506d486def18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A Few Notes on Accuracy\n",
    "### Accuracy isn't Everything\n",
    "While accuracy is a useful metric for many classification problems, relying solely on it might not be sufficient for all scenarios, especially for imbalanced datasets where the number of instances across classes is not evenly distributed. In such cases, other metrics like precision, recall, F1-score, or the confusion matrix provide a more nuanced view of the model's performance. These are all metrics we can visualize in our Experiments tab! \n",
    "### Dataset Characteristics\n",
    "The Iris dataset is relatively small and simple, with clear boundaries between classes for the most part. Such datasets can often lead to high-performing models, which might not be the case with more complex or noisy datasets.\n",
    "### Overfitting\n",
    "Overfitting is kind of like when you cram all night for a test, memorizing every single answer by heart. Sure, you ace the test the next day because you've got all those specific answers down pat. But then, when you're thrown into the real world, trying to apply what you \"learned\"? Suddenly, you find yourself a bit lost. That's because you were super focused on those exact questions and answers, not really grasping the broader concepts or thinking about how to tackle problems you haven't seen before.  In machine learning, overfitting happens when your model becomes gantastic at predicting the data it was trained on, but stumbles when it encounters new, unseen data. The real aim isn't just to get your model to nail the test data (though it feels great when it does). Instead, it's about prepping your model to perform well out in the wild, on real-world data it hasn't seen before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e991ef-1580-49d8-84d7-dc1a22fbb68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
